{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7065075d-a692-4b81-9655-116122b24a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41da94f7-016a-46c4-b664-589f23b96ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"train.csv\")\n",
    "test_labels = pd.read_csv(\"test.csv\")\n",
    "validation_labels = pd.read_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23098a51-ab66-427a-b0b1-0d57b8743104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, labels, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(labels)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_image(img_path):\n",
    "        imagine = np.array(Image.open(img_path))\n",
    "        imagine = np.ravel(imagine.copy())\n",
    "        if(imagine.shape == (6400, )):\n",
    "            imagine = np.concatenate((imagine, imagine, imagine))\n",
    "        imagine = np.reshape(imagine, (80, 80, 3))\n",
    "        return np.reshape(imagine, (80, 80, 3))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) + \".png\"\n",
    "        #print(img_path)\n",
    "        image = self.read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c23fdf64-f488-4bcb-9703-beec3d4a830c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(\"train.csv\", \"train\", transform = ToTensor())\n",
    "test_data = CustomImageDataset(\"test.csv\", \"test\", transform = ToTensor())\n",
    "validation_data = CustomImageDataset(\"validation.csv\", \"validation\", transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0ef1f01-8669-438c-90b6-cae8430b2b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReteaNeuronala(nn.Module):\n",
    "    def __init__(self, n_layers, n_neurons):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.ModuleList()#e o lista dar se intelege bine cu CUDA\n",
    "        self.first_layer = nn.Linear(80 * 80 * 3, n_neurons)\n",
    "        self.layers.append(self.first_layer)\n",
    "        for _ in range(n_layers):\n",
    "            self.layers.append(nn.Linear(n_neurons, n_neurons))\n",
    "        self.output_layer = nn.Linear(n_neurons, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        # x = F.relu(self.first_layer(x))\n",
    "        # x = F.relu(self.second_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3f3fba4-1b94-44a4-ab0f-8c5f8fb8a53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 64)\n",
    "test_loader = DataLoader(test_data, batch_size = 64)\n",
    "validation_loader = DataLoader(validation_data, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a228eaa6-a69e-4f05-bb1c-38ba3183562e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creem retea si definim algoritmul de optimizare\n",
    "model = ReteaNeuronala(3, 2352)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9f0ace3-54b0-4f08-bae1-cf04d84c2d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "=== Epoch1===\n",
      "Batch index0, loss:1.100909\n",
      "Batch index100, loss:1.096499\n",
      "=== Epoch2===\n",
      "Batch index0, loss:1.091160\n",
      "Batch index100, loss:1.093425\n",
      "=== Epoch3===\n",
      "Batch index0, loss:1.082553\n",
      "Batch index100, loss:1.090652\n",
      "=== Epoch4===\n",
      "Batch index0, loss:1.070438\n",
      "Batch index100, loss:1.089952\n",
      "=== Epoch5===\n",
      "Batch index0, loss:1.058501\n",
      "Batch index100, loss:1.092588\n",
      "=== Epoch6===\n",
      "Batch index0, loss:1.051515\n",
      "Batch index100, loss:1.095601\n",
      "=== Epoch7===\n",
      "Batch index0, loss:1.050154\n",
      "Batch index100, loss:1.097607\n",
      "=== Epoch8===\n",
      "Batch index0, loss:1.052832\n",
      "Batch index100, loss:1.099731\n",
      "=== Epoch9===\n",
      "Batch index0, loss:1.057366\n",
      "Batch index100, loss:1.101680\n",
      "=== Epoch10===\n",
      "Batch index0, loss:1.062680\n",
      "Batch index100, loss:1.104333\n",
      "=== Epoch11===\n",
      "Batch index0, loss:1.068392\n",
      "Batch index100, loss:1.107011\n",
      "=== Epoch12===\n",
      "Batch index0, loss:1.074110\n",
      "Batch index100, loss:1.110250\n",
      "=== Epoch13===\n",
      "Batch index0, loss:1.082430\n",
      "Batch index100, loss:1.115026\n",
      "=== Epoch14===\n",
      "Batch index0, loss:1.093111\n",
      "Batch index100, loss:1.120065\n",
      "=== Epoch15===\n",
      "Batch index0, loss:1.104560\n",
      "Batch index100, loss:1.124608\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 15\n",
    "print(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train(True)\n",
    "for i in range(NUM_EPOCHS):\n",
    "    print(f\"=== Epoch{i + 1}===\")\n",
    "    for batch, (image_batch, labels_batch) in enumerate(train_loader):\n",
    "        image_batch = image_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        #print(image_batch.shape)\n",
    "        #print(labels_batch.shape)\n",
    "\n",
    "        pred = model(image_batch)\n",
    "        #print(pred.shape)\n",
    "        loss = loss_function(pred, labels_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch%100 == 0:\n",
    "            loss = loss.item()\n",
    "            print(f\"Batch index{batch}, loss:{loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9cb5d8d9-0748-4e56-823b-1dcdab7ba266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.3%, Loss: 0.017274 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "test_loss = 0\n",
    "size = len(validation_loader.dataset)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for image_batch, labels_batch in validation_loader:\n",
    "        image_batch = image_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        pred = model(image_batch)\n",
    "        test_loss += loss_function(pred, labels_batch).item()\n",
    "        correct += (pred.argmax(1) == labels_batch).type(torch.float).sum().item()\n",
    "correct /= size\n",
    "test_loss /= size\n",
    "print(f\"Accuracy: {(100*correct):>0.1f}%, Loss: {test_loss:>8f} \\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
