{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgricultureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.target_shape = (128, 128, 125)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx].id)\n",
    "        print(img.shape)\n",
    "        img = np.load(img_path) \n",
    "\n",
    "        \n",
    "        if img.ndim != 3:\n",
    "            raise ValueError(f\"Image at index {idx} has invalid shape {img.shape}\")\n",
    "\n",
    "        H, W, D = img.shape\n",
    "        TH, TW, TD = self.target_shape\n",
    "\n",
    "        padded = np.zeros(self.target_shape, dtype=np.float32)\n",
    "\n",
    "        copy_H = min(H, TH)\n",
    "        copy_W = min(W, TW)\n",
    "        copy_D = min(D, TD)\n",
    "\n",
    "        padded[:copy_H, :copy_W, :copy_D] = img[:copy_H, :copy_W, :copy_D]\n",
    "\n",
    "        multi_spectral_image = torch.from_numpy(padded)\n",
    "\n",
    "        if self.transform:\n",
    "            multi_spectral_image = self.transform(multi_spectral_image)\n",
    "\n",
    "        label = float(self.df.iloc[idx].label)\n",
    "        return multi_spectral_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AgricultureDataset(train_df, 'ot/ot')\n",
    "test_dataset = AgricultureDataset(test_df, 'ot/ot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1785856 into shape (128,128,125)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m921\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36mAgricultureDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     13\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m---> 14\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\numpy\\lib\\format.py:831\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    829\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 831\u001b[0m         array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1785856 into shape (128,128,125)"
     ]
    }
   ],
   "source": [
    "train_dataset[921]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 16, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2048000, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMyModel(lightning.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        preds = self.model(x).float()\n",
    "        loss = torch.nn.functional.mse_loss(preds, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-66.6054]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainableModel = LitMyModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Fabi\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | MyModel | 2.1 B  | train\n",
      "------------------------------------------\n",
      "2.1 B     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 B     Total params\n",
      "8,390.713 Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Fabi\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bd8b4b038849fb88a65f4c93aa6fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabi\\AppData\\Local\\Temp\\ipykernel_16976\\714228663.py:10: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(preds, y)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m lightning\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainableModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    595\u001b[0m     ckpt_path,\n\u001b[0;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m )\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         closure()\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    179\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\core\\module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1273\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1302\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(optimizer, model\u001b[38;5;241m=\u001b[39mmodel, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\optim\\adam.py:202\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 202\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    205\u001b[0m     params_with_grad: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     98\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     optimizer: Steppable,\n\u001b[0;32m    100\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:140\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_fn()\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:241\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[1;34m(loss)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:213\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[1;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    211\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mbackward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, optimizer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:73\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[1;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     61\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     model\u001b[38;5;241m.\u001b[39mbackward(tensor, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\core\\module.py:1097\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[1;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fabric\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1097\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "trainer = lightning.Trainer()\n",
    "trainer.fit(trainableModel, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[42][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128, 125]) 0\n",
      "torch.Size([128, 128, 125]) 1\n",
      "torch.Size([128, 128, 125]) 2\n",
      "torch.Size([128, 128, 125]) 3\n",
      "torch.Size([128, 128, 125]) 4\n",
      "torch.Size([128, 128, 125]) 5\n",
      "torch.Size([128, 128, 125]) 6\n",
      "torch.Size([128, 128, 125]) 7\n",
      "torch.Size([128, 128, 125]) 8\n",
      "torch.Size([128, 128, 125]) 9\n",
      "torch.Size([128, 128, 125]) 10\n",
      "torch.Size([128, 128, 125]) 11\n",
      "torch.Size([128, 128, 125]) 12\n",
      "torch.Size([128, 128, 125]) 13\n",
      "torch.Size([128, 128, 125]) 14\n",
      "torch.Size([128, 128, 125]) 15\n",
      "torch.Size([128, 128, 125]) 16\n",
      "torch.Size([128, 128, 125]) 17\n",
      "torch.Size([128, 128, 125]) 18\n",
      "torch.Size([128, 128, 125]) 19\n",
      "torch.Size([128, 128, 125]) 20\n",
      "torch.Size([128, 128, 125]) 21\n",
      "torch.Size([128, 128, 125]) 22\n",
      "torch.Size([128, 128, 125]) 23\n",
      "torch.Size([128, 128, 125]) 24\n",
      "torch.Size([128, 128, 125]) 25\n",
      "torch.Size([128, 128, 125]) 26\n",
      "torch.Size([128, 128, 125]) 27\n",
      "torch.Size([128, 128, 125]) 28\n",
      "torch.Size([128, 128, 125]) 29\n",
      "torch.Size([128, 128, 125]) 30\n",
      "torch.Size([128, 128, 125]) 31\n",
      "torch.Size([128, 128, 125]) 32\n",
      "torch.Size([128, 128, 125]) 33\n",
      "torch.Size([128, 128, 125]) 34\n",
      "torch.Size([128, 128, 125]) 35\n",
      "torch.Size([128, 128, 125]) 36\n",
      "torch.Size([128, 128, 125]) 37\n",
      "torch.Size([128, 128, 125]) 38\n",
      "torch.Size([128, 128, 125]) 39\n",
      "torch.Size([128, 128, 125]) 40\n",
      "torch.Size([128, 128, 125]) 41\n",
      "torch.Size([128, 128, 125]) 42\n",
      "torch.Size([128, 128, 125]) 43\n",
      "torch.Size([128, 128, 125]) 44\n",
      "torch.Size([128, 128, 125]) 45\n",
      "torch.Size([128, 128, 125]) 46\n",
      "torch.Size([128, 128, 125]) 47\n",
      "torch.Size([128, 128, 125]) 48\n",
      "torch.Size([128, 128, 125]) 49\n",
      "torch.Size([128, 128, 125]) 50\n",
      "torch.Size([128, 128, 125]) 51\n",
      "torch.Size([128, 128, 125]) 52\n",
      "torch.Size([128, 128, 125]) 53\n",
      "torch.Size([128, 128, 125]) 54\n",
      "torch.Size([128, 128, 125]) 55\n",
      "torch.Size([128, 128, 125]) 56\n",
      "torch.Size([128, 128, 125]) 57\n",
      "torch.Size([128, 128, 125]) 58\n",
      "torch.Size([128, 128, 125]) 59\n",
      "torch.Size([128, 128, 125]) 60\n",
      "torch.Size([128, 128, 125]) 61\n",
      "torch.Size([128, 128, 125]) 62\n",
      "torch.Size([128, 128, 125]) 63\n",
      "torch.Size([128, 128, 125]) 64\n",
      "torch.Size([128, 128, 125]) 65\n",
      "torch.Size([128, 128, 125]) 66\n",
      "torch.Size([128, 128, 125]) 67\n",
      "torch.Size([128, 128, 125]) 68\n",
      "torch.Size([128, 128, 125]) 69\n",
      "torch.Size([128, 128, 125]) 70\n",
      "torch.Size([128, 128, 125]) 71\n",
      "torch.Size([128, 128, 125]) 72\n",
      "torch.Size([128, 128, 125]) 73\n",
      "torch.Size([128, 128, 125]) 74\n",
      "torch.Size([128, 128, 125]) 75\n",
      "torch.Size([128, 128, 125]) 76\n",
      "torch.Size([128, 128, 125]) 77\n",
      "torch.Size([128, 128, 125]) 78\n",
      "torch.Size([128, 128, 125]) 79\n",
      "torch.Size([128, 128, 125]) 80\n",
      "torch.Size([128, 128, 125]) 81\n",
      "torch.Size([128, 128, 125]) 82\n",
      "torch.Size([128, 128, 125]) 83\n",
      "torch.Size([128, 128, 125]) 84\n",
      "torch.Size([128, 128, 125]) 85\n",
      "torch.Size([128, 128, 125]) 86\n",
      "torch.Size([128, 128, 125]) 87\n",
      "torch.Size([128, 128, 125]) 88\n",
      "torch.Size([128, 128, 125]) 89\n",
      "torch.Size([128, 128, 125]) 90\n",
      "torch.Size([128, 128, 125]) 91\n",
      "torch.Size([128, 128, 125]) 92\n",
      "torch.Size([128, 128, 125]) 93\n",
      "torch.Size([128, 128, 125]) 94\n",
      "torch.Size([128, 128, 125]) 95\n",
      "torch.Size([128, 128, 125]) 96\n",
      "torch.Size([128, 128, 125]) 97\n",
      "torch.Size([128, 128, 125]) 98\n",
      "torch.Size([128, 128, 125]) 99\n",
      "torch.Size([128, 128, 125]) 100\n",
      "torch.Size([128, 128, 125]) 101\n",
      "torch.Size([128, 128, 125]) 102\n",
      "torch.Size([128, 128, 125]) 103\n",
      "torch.Size([128, 128, 125]) 104\n",
      "torch.Size([128, 128, 125]) 105\n",
      "torch.Size([128, 128, 125]) 106\n",
      "torch.Size([128, 128, 125]) 107\n",
      "torch.Size([128, 128, 125]) 108\n",
      "torch.Size([128, 128, 125]) 109\n",
      "torch.Size([128, 128, 125]) 110\n",
      "torch.Size([128, 128, 125]) 111\n",
      "torch.Size([128, 128, 125]) 112\n",
      "torch.Size([128, 128, 125]) 113\n",
      "torch.Size([128, 128, 125]) 114\n",
      "torch.Size([128, 128, 125]) 115\n",
      "torch.Size([128, 128, 125]) 116\n",
      "torch.Size([128, 128, 125]) 117\n",
      "torch.Size([128, 128, 125]) 118\n",
      "torch.Size([128, 128, 125]) 119\n",
      "torch.Size([128, 128, 125]) 120\n",
      "torch.Size([128, 128, 125]) 121\n",
      "torch.Size([128, 128, 125]) 122\n",
      "torch.Size([128, 128, 125]) 123\n",
      "torch.Size([128, 128, 125]) 124\n",
      "torch.Size([128, 128, 125]) 125\n",
      "torch.Size([128, 128, 125]) 126\n",
      "torch.Size([128, 128, 125]) 127\n",
      "torch.Size([128, 128, 125]) 128\n",
      "torch.Size([128, 128, 125]) 129\n",
      "torch.Size([128, 128, 125]) 130\n",
      "torch.Size([128, 128, 125]) 131\n",
      "torch.Size([128, 128, 125]) 132\n",
      "torch.Size([128, 128, 125]) 133\n",
      "torch.Size([128, 128, 125]) 134\n",
      "torch.Size([128, 128, 125]) 135\n",
      "torch.Size([128, 128, 125]) 136\n",
      "torch.Size([128, 128, 125]) 137\n",
      "torch.Size([128, 128, 125]) 138\n",
      "torch.Size([128, 128, 125]) 139\n",
      "torch.Size([128, 128, 125]) 140\n",
      "torch.Size([128, 128, 125]) 141\n",
      "torch.Size([128, 128, 125]) 142\n",
      "torch.Size([128, 128, 125]) 143\n",
      "torch.Size([128, 128, 125]) 144\n",
      "torch.Size([128, 128, 125]) 145\n",
      "torch.Size([128, 128, 125]) 146\n",
      "torch.Size([128, 128, 125]) 147\n",
      "torch.Size([128, 128, 125]) 148\n",
      "torch.Size([128, 128, 125]) 149\n",
      "torch.Size([128, 128, 125]) 150\n",
      "torch.Size([128, 128, 125]) 151\n",
      "torch.Size([128, 128, 125]) 152\n",
      "torch.Size([128, 128, 125]) 153\n",
      "torch.Size([128, 128, 125]) 154\n",
      "torch.Size([128, 128, 125]) 155\n",
      "torch.Size([128, 128, 125]) 156\n",
      "torch.Size([128, 128, 125]) 157\n",
      "torch.Size([128, 128, 125]) 158\n",
      "torch.Size([128, 128, 125]) 159\n",
      "torch.Size([128, 128, 125]) 160\n",
      "torch.Size([128, 128, 125]) 161\n",
      "torch.Size([128, 128, 125]) 162\n",
      "torch.Size([128, 128, 125]) 163\n",
      "torch.Size([128, 128, 125]) 164\n",
      "torch.Size([128, 128, 125]) 165\n",
      "torch.Size([128, 128, 125]) 166\n",
      "torch.Size([128, 128, 125]) 167\n",
      "torch.Size([128, 128, 125]) 168\n",
      "torch.Size([128, 128, 125]) 169\n",
      "torch.Size([128, 128, 125]) 170\n",
      "torch.Size([128, 128, 125]) 171\n",
      "torch.Size([128, 128, 125]) 172\n",
      "torch.Size([128, 128, 125]) 173\n",
      "torch.Size([128, 128, 125]) 174\n",
      "torch.Size([128, 128, 125]) 175\n",
      "torch.Size([128, 128, 125]) 176\n",
      "torch.Size([128, 128, 125]) 177\n",
      "torch.Size([128, 128, 125]) 178\n",
      "torch.Size([128, 128, 125]) 179\n",
      "torch.Size([128, 128, 125]) 180\n",
      "torch.Size([128, 128, 125]) 181\n",
      "torch.Size([128, 128, 125]) 182\n",
      "torch.Size([128, 128, 125]) 183\n",
      "torch.Size([128, 128, 125]) 184\n",
      "torch.Size([128, 128, 125]) 185\n",
      "torch.Size([128, 128, 125]) 186\n",
      "torch.Size([128, 128, 125]) 187\n",
      "torch.Size([128, 128, 125]) 188\n",
      "torch.Size([128, 128, 125]) 189\n",
      "torch.Size([128, 128, 125]) 190\n",
      "torch.Size([128, 128, 125]) 191\n",
      "torch.Size([128, 128, 125]) 192\n",
      "torch.Size([128, 128, 125]) 193\n",
      "torch.Size([128, 128, 125]) 194\n",
      "torch.Size([128, 128, 125]) 195\n",
      "torch.Size([128, 128, 125]) 196\n",
      "torch.Size([128, 128, 125]) 197\n",
      "torch.Size([128, 128, 125]) 198\n",
      "torch.Size([128, 128, 125]) 199\n",
      "torch.Size([128, 128, 125]) 200\n",
      "torch.Size([128, 128, 125]) 201\n",
      "torch.Size([128, 128, 125]) 202\n",
      "torch.Size([128, 128, 125]) 203\n",
      "torch.Size([128, 128, 125]) 204\n",
      "torch.Size([128, 128, 125]) 205\n",
      "torch.Size([128, 128, 125]) 206\n",
      "torch.Size([128, 128, 125]) 207\n",
      "torch.Size([128, 128, 125]) 208\n",
      "torch.Size([128, 128, 125]) 209\n",
      "torch.Size([128, 128, 125]) 210\n",
      "torch.Size([128, 128, 125]) 211\n",
      "torch.Size([128, 128, 125]) 212\n",
      "torch.Size([128, 128, 125]) 213\n",
      "torch.Size([128, 128, 125]) 214\n",
      "torch.Size([128, 128, 125]) 215\n",
      "torch.Size([128, 128, 125]) 216\n",
      "torch.Size([128, 128, 125]) 217\n",
      "torch.Size([128, 128, 125]) 218\n",
      "torch.Size([128, 128, 125]) 219\n",
      "torch.Size([128, 128, 125]) 220\n",
      "torch.Size([128, 128, 125]) 221\n",
      "torch.Size([128, 128, 125]) 222\n",
      "torch.Size([128, 128, 125]) 223\n",
      "torch.Size([128, 128, 125]) 224\n",
      "torch.Size([128, 128, 125]) 225\n",
      "torch.Size([128, 128, 125]) 226\n",
      "torch.Size([128, 128, 125]) 227\n",
      "torch.Size([128, 128, 125]) 228\n",
      "torch.Size([128, 128, 125]) 229\n",
      "torch.Size([128, 128, 125]) 230\n",
      "torch.Size([128, 128, 125]) 231\n",
      "torch.Size([128, 128, 125]) 232\n",
      "torch.Size([128, 128, 125]) 233\n",
      "torch.Size([128, 128, 125]) 234\n",
      "torch.Size([128, 128, 125]) 235\n",
      "torch.Size([128, 128, 125]) 236\n",
      "torch.Size([128, 128, 125]) 237\n",
      "torch.Size([128, 128, 125]) 238\n",
      "torch.Size([128, 128, 125]) 239\n",
      "torch.Size([128, 128, 125]) 240\n",
      "torch.Size([128, 128, 125]) 241\n",
      "torch.Size([128, 128, 125]) 242\n",
      "torch.Size([128, 128, 125]) 243\n",
      "torch.Size([128, 128, 125]) 244\n",
      "torch.Size([128, 128, 125]) 245\n",
      "torch.Size([128, 128, 125]) 246\n",
      "torch.Size([128, 128, 125]) 247\n",
      "torch.Size([128, 128, 125]) 248\n",
      "torch.Size([128, 128, 125]) 249\n",
      "torch.Size([128, 128, 125]) 250\n",
      "torch.Size([128, 128, 125]) 251\n",
      "torch.Size([128, 128, 125]) 252\n",
      "torch.Size([128, 128, 125]) 253\n",
      "torch.Size([128, 128, 125]) 254\n",
      "torch.Size([128, 128, 125]) 255\n",
      "torch.Size([128, 128, 125]) 256\n",
      "torch.Size([128, 128, 125]) 257\n",
      "torch.Size([128, 128, 125]) 258\n",
      "torch.Size([128, 128, 125]) 259\n",
      "torch.Size([128, 128, 125]) 260\n",
      "torch.Size([128, 128, 125]) 261\n",
      "torch.Size([128, 128, 125]) 262\n",
      "torch.Size([128, 128, 125]) 263\n",
      "torch.Size([128, 128, 125]) 264\n",
      "torch.Size([128, 128, 125]) 265\n",
      "torch.Size([128, 128, 125]) 266\n",
      "torch.Size([128, 128, 125]) 267\n",
      "torch.Size([128, 128, 125]) 268\n",
      "torch.Size([128, 128, 125]) 269\n",
      "torch.Size([128, 128, 125]) 270\n",
      "torch.Size([128, 128, 125]) 271\n",
      "torch.Size([128, 128, 125]) 272\n",
      "torch.Size([128, 128, 125]) 273\n",
      "torch.Size([128, 128, 125]) 274\n",
      "torch.Size([128, 128, 125]) 275\n",
      "torch.Size([128, 128, 125]) 276\n",
      "torch.Size([128, 128, 125]) 277\n",
      "torch.Size([128, 128, 125]) 278\n",
      "torch.Size([128, 128, 125]) 279\n",
      "torch.Size([128, 128, 125]) 280\n",
      "torch.Size([128, 128, 125]) 281\n",
      "torch.Size([128, 128, 125]) 282\n",
      "torch.Size([128, 128, 125]) 283\n",
      "torch.Size([128, 128, 125]) 284\n",
      "torch.Size([128, 128, 125]) 285\n",
      "torch.Size([128, 128, 125]) 286\n",
      "torch.Size([128, 128, 125]) 287\n",
      "torch.Size([128, 128, 125]) 288\n",
      "torch.Size([128, 128, 125]) 289\n",
      "torch.Size([128, 128, 125]) 290\n",
      "torch.Size([128, 128, 125]) 291\n",
      "torch.Size([128, 128, 125]) 292\n",
      "torch.Size([128, 128, 125]) 293\n",
      "torch.Size([128, 128, 125]) 294\n",
      "torch.Size([128, 128, 125]) 295\n",
      "torch.Size([128, 128, 125]) 296\n",
      "torch.Size([128, 128, 125]) 297\n",
      "torch.Size([128, 128, 125]) 298\n",
      "torch.Size([128, 128, 125]) 299\n",
      "torch.Size([128, 128, 125]) 300\n",
      "torch.Size([128, 128, 125]) 301\n",
      "torch.Size([128, 128, 125]) 302\n",
      "torch.Size([128, 128, 125]) 303\n",
      "torch.Size([128, 128, 125]) 304\n",
      "torch.Size([128, 128, 125]) 305\n",
      "torch.Size([128, 128, 125]) 306\n",
      "torch.Size([128, 128, 125]) 307\n",
      "torch.Size([128, 128, 125]) 308\n",
      "torch.Size([128, 128, 125]) 309\n",
      "torch.Size([128, 128, 125]) 310\n",
      "torch.Size([128, 128, 125]) 311\n",
      "torch.Size([128, 128, 125]) 312\n",
      "torch.Size([128, 128, 125]) 313\n",
      "torch.Size([128, 128, 125]) 314\n",
      "torch.Size([128, 128, 125]) 315\n",
      "torch.Size([128, 128, 125]) 316\n",
      "torch.Size([128, 128, 125]) 317\n",
      "torch.Size([128, 128, 125]) 318\n",
      "torch.Size([128, 128, 125]) 319\n",
      "torch.Size([128, 128, 125]) 320\n",
      "torch.Size([128, 128, 125]) 321\n",
      "torch.Size([128, 128, 125]) 322\n",
      "torch.Size([128, 128, 125]) 323\n",
      "torch.Size([128, 128, 125]) 324\n",
      "torch.Size([128, 128, 125]) 325\n",
      "torch.Size([128, 128, 125]) 326\n",
      "torch.Size([128, 128, 125]) 327\n",
      "torch.Size([128, 128, 125]) 328\n",
      "torch.Size([128, 128, 125]) 329\n",
      "torch.Size([128, 128, 125]) 330\n",
      "torch.Size([128, 128, 125]) 331\n",
      "torch.Size([128, 128, 125]) 332\n",
      "torch.Size([128, 128, 125]) 333\n",
      "torch.Size([128, 128, 125]) 334\n",
      "torch.Size([128, 128, 125]) 335\n",
      "torch.Size([128, 128, 125]) 336\n",
      "torch.Size([128, 128, 125]) 337\n",
      "torch.Size([128, 128, 125]) 338\n",
      "torch.Size([128, 128, 125]) 339\n",
      "torch.Size([128, 128, 125]) 340\n",
      "torch.Size([128, 128, 125]) 341\n",
      "torch.Size([128, 128, 125]) 342\n",
      "torch.Size([128, 128, 125]) 343\n",
      "torch.Size([128, 128, 125]) 344\n",
      "torch.Size([128, 128, 125]) 345\n",
      "torch.Size([128, 128, 125]) 346\n",
      "torch.Size([128, 128, 125]) 347\n",
      "torch.Size([128, 128, 125]) 348\n",
      "torch.Size([128, 128, 125]) 349\n",
      "torch.Size([128, 128, 125]) 350\n",
      "torch.Size([128, 128, 125]) 351\n",
      "torch.Size([128, 128, 125]) 352\n",
      "torch.Size([128, 128, 125]) 353\n",
      "torch.Size([128, 128, 125]) 354\n",
      "torch.Size([128, 128, 125]) 355\n",
      "torch.Size([128, 128, 125]) 356\n",
      "torch.Size([128, 128, 125]) 357\n",
      "torch.Size([128, 128, 125]) 358\n",
      "torch.Size([128, 128, 125]) 359\n",
      "torch.Size([128, 128, 125]) 360\n",
      "torch.Size([128, 128, 125]) 361\n",
      "torch.Size([128, 128, 125]) 362\n",
      "torch.Size([128, 128, 125]) 363\n",
      "torch.Size([128, 128, 125]) 364\n",
      "torch.Size([128, 128, 125]) 365\n",
      "torch.Size([128, 128, 125]) 366\n",
      "torch.Size([128, 128, 125]) 367\n",
      "torch.Size([128, 128, 125]) 368\n",
      "torch.Size([128, 128, 125]) 369\n",
      "torch.Size([128, 128, 125]) 370\n",
      "torch.Size([128, 128, 125]) 371\n",
      "torch.Size([128, 128, 125]) 372\n",
      "torch.Size([128, 128, 125]) 373\n",
      "torch.Size([128, 128, 125]) 374\n",
      "torch.Size([128, 128, 125]) 375\n",
      "torch.Size([128, 128, 125]) 376\n",
      "torch.Size([128, 128, 125]) 377\n",
      "torch.Size([128, 128, 125]) 378\n",
      "torch.Size([128, 128, 125]) 379\n",
      "torch.Size([128, 128, 125]) 380\n",
      "torch.Size([128, 128, 125]) 381\n",
      "torch.Size([128, 128, 125]) 382\n",
      "torch.Size([128, 128, 125]) 383\n",
      "torch.Size([128, 128, 125]) 384\n",
      "torch.Size([128, 128, 125]) 385\n",
      "torch.Size([128, 128, 125]) 386\n",
      "torch.Size([128, 128, 125]) 387\n",
      "torch.Size([128, 128, 125]) 388\n",
      "torch.Size([128, 128, 125]) 389\n",
      "torch.Size([128, 128, 125]) 390\n",
      "torch.Size([128, 128, 125]) 391\n",
      "torch.Size([128, 128, 125]) 392\n",
      "torch.Size([128, 128, 125]) 393\n",
      "torch.Size([128, 128, 125]) 394\n",
      "torch.Size([128, 128, 125]) 395\n",
      "torch.Size([128, 128, 125]) 396\n",
      "torch.Size([128, 128, 125]) 397\n",
      "torch.Size([128, 128, 125]) 398\n",
      "torch.Size([128, 128, 125]) 399\n",
      "torch.Size([128, 128, 125]) 400\n",
      "torch.Size([128, 128, 125]) 401\n",
      "torch.Size([128, 128, 125]) 402\n",
      "torch.Size([128, 128, 125]) 403\n",
      "torch.Size([128, 128, 125]) 404\n",
      "torch.Size([128, 128, 125]) 405\n",
      "torch.Size([128, 128, 125]) 406\n",
      "torch.Size([128, 128, 125]) 407\n",
      "torch.Size([128, 128, 125]) 408\n",
      "torch.Size([128, 128, 125]) 409\n",
      "torch.Size([128, 128, 125]) 410\n",
      "torch.Size([128, 128, 125]) 411\n",
      "torch.Size([128, 128, 125]) 412\n",
      "torch.Size([128, 128, 125]) 413\n",
      "torch.Size([128, 128, 125]) 414\n",
      "torch.Size([128, 128, 125]) 415\n",
      "torch.Size([128, 128, 125]) 416\n",
      "torch.Size([128, 128, 125]) 417\n",
      "torch.Size([128, 128, 125]) 418\n",
      "torch.Size([128, 128, 125]) 419\n",
      "torch.Size([128, 128, 125]) 420\n",
      "torch.Size([128, 128, 125]) 421\n",
      "torch.Size([128, 128, 125]) 422\n",
      "torch.Size([128, 128, 125]) 423\n",
      "torch.Size([128, 128, 125]) 424\n",
      "torch.Size([128, 128, 125]) 425\n",
      "torch.Size([128, 128, 125]) 426\n",
      "torch.Size([128, 128, 125]) 427\n",
      "torch.Size([128, 128, 125]) 428\n",
      "torch.Size([128, 128, 125]) 429\n",
      "torch.Size([128, 128, 125]) 430\n",
      "torch.Size([128, 128, 125]) 431\n",
      "torch.Size([128, 128, 125]) 432\n",
      "torch.Size([128, 128, 125]) 433\n",
      "torch.Size([128, 128, 125]) 434\n",
      "torch.Size([128, 128, 125]) 435\n",
      "torch.Size([128, 128, 125]) 436\n",
      "torch.Size([128, 128, 125]) 437\n",
      "torch.Size([128, 128, 125]) 438\n",
      "torch.Size([128, 128, 125]) 439\n",
      "torch.Size([128, 128, 125]) 440\n",
      "torch.Size([128, 128, 125]) 441\n",
      "torch.Size([128, 128, 125]) 442\n",
      "torch.Size([128, 128, 125]) 443\n",
      "torch.Size([128, 128, 125]) 444\n",
      "torch.Size([128, 128, 125]) 445\n",
      "torch.Size([128, 128, 125]) 446\n",
      "torch.Size([128, 128, 125]) 447\n",
      "torch.Size([128, 128, 125]) 448\n",
      "torch.Size([128, 128, 125]) 449\n",
      "torch.Size([128, 128, 125]) 450\n",
      "torch.Size([128, 128, 125]) 451\n",
      "torch.Size([128, 128, 125]) 452\n",
      "torch.Size([128, 128, 125]) 453\n",
      "torch.Size([128, 128, 125]) 454\n",
      "torch.Size([128, 128, 125]) 455\n",
      "torch.Size([128, 128, 125]) 456\n",
      "torch.Size([128, 128, 125]) 457\n",
      "torch.Size([128, 128, 125]) 458\n",
      "torch.Size([128, 128, 125]) 459\n",
      "torch.Size([128, 128, 125]) 460\n",
      "torch.Size([128, 128, 125]) 461\n",
      "torch.Size([128, 128, 125]) 462\n",
      "torch.Size([128, 128, 125]) 463\n",
      "torch.Size([128, 128, 125]) 464\n",
      "torch.Size([128, 128, 125]) 465\n",
      "torch.Size([128, 128, 125]) 466\n",
      "torch.Size([128, 128, 125]) 467\n",
      "torch.Size([128, 128, 125]) 468\n",
      "torch.Size([128, 128, 125]) 469\n",
      "torch.Size([128, 128, 125]) 470\n",
      "torch.Size([128, 128, 125]) 471\n",
      "torch.Size([128, 128, 125]) 472\n",
      "torch.Size([128, 128, 125]) 473\n",
      "torch.Size([128, 128, 125]) 474\n",
      "torch.Size([128, 128, 125]) 475\n",
      "torch.Size([128, 128, 125]) 476\n",
      "torch.Size([128, 128, 125]) 477\n",
      "torch.Size([128, 128, 125]) 478\n",
      "torch.Size([128, 128, 125]) 479\n",
      "torch.Size([128, 128, 125]) 480\n",
      "torch.Size([128, 128, 125]) 481\n",
      "torch.Size([128, 128, 125]) 482\n",
      "torch.Size([128, 128, 125]) 483\n",
      "torch.Size([128, 128, 125]) 484\n",
      "torch.Size([128, 128, 125]) 485\n",
      "torch.Size([128, 128, 125]) 486\n",
      "torch.Size([128, 128, 125]) 487\n",
      "torch.Size([128, 128, 125]) 488\n",
      "torch.Size([128, 128, 125]) 489\n",
      "torch.Size([128, 128, 125]) 490\n",
      "torch.Size([128, 128, 125]) 491\n",
      "torch.Size([128, 128, 125]) 492\n",
      "torch.Size([128, 128, 125]) 493\n",
      "torch.Size([128, 128, 125]) 494\n",
      "torch.Size([128, 128, 125]) 495\n",
      "torch.Size([128, 128, 125]) 496\n",
      "torch.Size([128, 128, 125]) 497\n",
      "torch.Size([128, 128, 125]) 498\n",
      "torch.Size([128, 128, 125]) 499\n",
      "torch.Size([128, 128, 125]) 500\n",
      "torch.Size([128, 128, 125]) 501\n",
      "torch.Size([128, 128, 125]) 502\n",
      "torch.Size([128, 128, 125]) 503\n",
      "torch.Size([128, 128, 125]) 504\n",
      "torch.Size([128, 128, 125]) 505\n",
      "torch.Size([128, 128, 125]) 506\n",
      "torch.Size([128, 128, 125]) 507\n",
      "torch.Size([128, 128, 125]) 508\n",
      "torch.Size([128, 128, 125]) 509\n",
      "torch.Size([128, 128, 125]) 510\n",
      "torch.Size([128, 128, 125]) 511\n",
      "torch.Size([128, 128, 125]) 512\n",
      "torch.Size([128, 128, 125]) 513\n",
      "torch.Size([128, 128, 125]) 514\n",
      "torch.Size([128, 128, 125]) 515\n",
      "torch.Size([128, 128, 125]) 516\n",
      "torch.Size([128, 128, 125]) 517\n",
      "torch.Size([128, 128, 125]) 518\n",
      "torch.Size([128, 128, 125]) 519\n",
      "torch.Size([128, 128, 125]) 520\n",
      "torch.Size([128, 128, 125]) 521\n",
      "torch.Size([128, 128, 125]) 522\n",
      "torch.Size([128, 128, 125]) 523\n",
      "torch.Size([128, 128, 125]) 524\n",
      "torch.Size([128, 128, 125]) 525\n",
      "torch.Size([128, 128, 125]) 526\n",
      "torch.Size([128, 128, 125]) 527\n",
      "torch.Size([128, 128, 125]) 528\n",
      "torch.Size([128, 128, 125]) 529\n",
      "torch.Size([128, 128, 125]) 530\n",
      "torch.Size([128, 128, 125]) 531\n",
      "torch.Size([128, 128, 125]) 532\n",
      "torch.Size([128, 128, 125]) 533\n",
      "torch.Size([128, 128, 125]) 534\n",
      "torch.Size([128, 128, 125]) 535\n",
      "torch.Size([128, 128, 125]) 536\n",
      "torch.Size([128, 128, 125]) 537\n",
      "torch.Size([128, 128, 125]) 538\n",
      "torch.Size([128, 128, 125]) 539\n",
      "torch.Size([128, 128, 125]) 540\n",
      "torch.Size([128, 128, 125]) 541\n",
      "torch.Size([128, 128, 125]) 542\n",
      "torch.Size([128, 128, 125]) 543\n",
      "torch.Size([128, 128, 125]) 544\n",
      "torch.Size([128, 128, 125]) 545\n",
      "torch.Size([128, 128, 125]) 546\n",
      "torch.Size([128, 128, 125]) 547\n",
      "torch.Size([128, 128, 125]) 548\n",
      "torch.Size([128, 128, 125]) 549\n",
      "torch.Size([128, 128, 125]) 550\n",
      "torch.Size([128, 128, 125]) 551\n",
      "torch.Size([128, 128, 125]) 552\n",
      "torch.Size([128, 128, 125]) 553\n",
      "torch.Size([128, 128, 125]) 554\n",
      "torch.Size([128, 128, 125]) 555\n",
      "torch.Size([128, 128, 125]) 556\n",
      "torch.Size([128, 128, 125]) 557\n",
      "torch.Size([128, 128, 125]) 558\n",
      "torch.Size([128, 128, 125]) 559\n",
      "torch.Size([128, 128, 125]) 560\n",
      "torch.Size([128, 128, 125]) 561\n",
      "torch.Size([128, 128, 125]) 562\n",
      "torch.Size([128, 128, 125]) 563\n",
      "torch.Size([128, 128, 125]) 564\n",
      "torch.Size([128, 128, 125]) 565\n",
      "torch.Size([128, 128, 125]) 566\n",
      "torch.Size([128, 128, 125]) 567\n",
      "torch.Size([128, 128, 125]) 568\n",
      "torch.Size([128, 128, 125]) 569\n",
      "torch.Size([128, 128, 125]) 570\n",
      "torch.Size([128, 128, 125]) 571\n",
      "torch.Size([128, 128, 125]) 572\n",
      "torch.Size([128, 128, 125]) 573\n",
      "torch.Size([128, 128, 125]) 574\n",
      "torch.Size([128, 128, 125]) 575\n",
      "torch.Size([128, 128, 125]) 576\n",
      "torch.Size([128, 128, 125]) 577\n",
      "torch.Size([128, 128, 125]) 578\n",
      "torch.Size([128, 128, 125]) 579\n",
      "torch.Size([128, 128, 125]) 580\n",
      "torch.Size([128, 128, 125]) 581\n",
      "torch.Size([128, 128, 125]) 582\n",
      "torch.Size([128, 128, 125]) 583\n",
      "torch.Size([128, 128, 125]) 584\n",
      "torch.Size([128, 128, 125]) 585\n",
      "torch.Size([128, 128, 125]) 586\n",
      "torch.Size([128, 128, 125]) 587\n",
      "torch.Size([128, 128, 125]) 588\n",
      "torch.Size([128, 128, 125]) 589\n",
      "torch.Size([128, 128, 125]) 590\n",
      "torch.Size([128, 128, 125]) 591\n",
      "torch.Size([128, 128, 125]) 592\n",
      "torch.Size([128, 128, 125]) 593\n",
      "torch.Size([128, 128, 125]) 594\n",
      "torch.Size([128, 128, 125]) 595\n",
      "torch.Size([128, 128, 125]) 596\n",
      "torch.Size([128, 128, 125]) 597\n",
      "torch.Size([128, 128, 125]) 598\n",
      "torch.Size([128, 128, 125]) 599\n",
      "torch.Size([128, 128, 125]) 600\n",
      "torch.Size([128, 128, 125]) 601\n",
      "torch.Size([128, 128, 125]) 602\n",
      "torch.Size([128, 128, 125]) 603\n",
      "torch.Size([128, 128, 125]) 604\n",
      "torch.Size([128, 128, 125]) 605\n",
      "torch.Size([128, 128, 125]) 606\n",
      "torch.Size([128, 128, 125]) 607\n",
      "torch.Size([128, 128, 125]) 608\n",
      "torch.Size([128, 128, 125]) 609\n",
      "torch.Size([128, 128, 125]) 610\n",
      "torch.Size([128, 128, 125]) 611\n",
      "torch.Size([128, 128, 125]) 612\n",
      "torch.Size([128, 128, 125]) 613\n",
      "torch.Size([128, 128, 125]) 614\n",
      "torch.Size([128, 128, 125]) 615\n",
      "torch.Size([128, 128, 125]) 616\n",
      "torch.Size([128, 128, 125]) 617\n",
      "torch.Size([128, 128, 125]) 618\n",
      "torch.Size([128, 128, 125]) 619\n",
      "torch.Size([128, 128, 125]) 620\n",
      "torch.Size([128, 128, 125]) 621\n",
      "torch.Size([128, 128, 125]) 622\n",
      "torch.Size([128, 128, 125]) 623\n",
      "torch.Size([128, 128, 125]) 624\n",
      "torch.Size([128, 128, 125]) 625\n",
      "torch.Size([128, 128, 125]) 626\n",
      "torch.Size([128, 128, 125]) 627\n",
      "torch.Size([128, 128, 125]) 628\n",
      "torch.Size([128, 128, 125]) 629\n",
      "torch.Size([128, 128, 125]) 630\n",
      "torch.Size([128, 128, 125]) 631\n",
      "torch.Size([128, 128, 125]) 632\n",
      "torch.Size([128, 128, 125]) 633\n",
      "torch.Size([128, 128, 125]) 634\n",
      "torch.Size([128, 128, 125]) 635\n",
      "torch.Size([128, 128, 125]) 636\n",
      "torch.Size([128, 128, 125]) 637\n",
      "torch.Size([128, 128, 125]) 638\n",
      "torch.Size([128, 128, 125]) 639\n",
      "torch.Size([128, 128, 125]) 640\n",
      "torch.Size([128, 128, 125]) 641\n",
      "torch.Size([128, 128, 125]) 642\n",
      "torch.Size([128, 128, 125]) 643\n",
      "torch.Size([128, 128, 125]) 644\n",
      "torch.Size([128, 128, 125]) 645\n",
      "torch.Size([128, 128, 125]) 646\n",
      "torch.Size([128, 128, 125]) 647\n",
      "torch.Size([128, 128, 125]) 648\n",
      "torch.Size([128, 128, 125]) 649\n",
      "torch.Size([128, 128, 125]) 650\n",
      "torch.Size([128, 128, 125]) 651\n",
      "torch.Size([128, 128, 125]) 652\n",
      "torch.Size([128, 128, 125]) 653\n",
      "torch.Size([128, 128, 125]) 654\n",
      "torch.Size([128, 128, 125]) 655\n",
      "torch.Size([128, 128, 125]) 656\n",
      "torch.Size([128, 128, 125]) 657\n",
      "torch.Size([128, 128, 125]) 658\n",
      "torch.Size([128, 128, 125]) 659\n",
      "torch.Size([128, 128, 125]) 660\n",
      "torch.Size([128, 128, 125]) 661\n",
      "torch.Size([128, 128, 125]) 662\n",
      "torch.Size([128, 128, 125]) 663\n",
      "torch.Size([128, 128, 125]) 664\n",
      "torch.Size([128, 128, 125]) 665\n",
      "torch.Size([128, 128, 125]) 666\n",
      "torch.Size([128, 128, 125]) 667\n",
      "torch.Size([128, 128, 125]) 668\n",
      "torch.Size([128, 128, 125]) 669\n",
      "torch.Size([128, 128, 125]) 670\n",
      "torch.Size([128, 128, 125]) 671\n",
      "torch.Size([128, 128, 125]) 672\n",
      "torch.Size([128, 128, 125]) 673\n",
      "torch.Size([128, 128, 125]) 674\n",
      "torch.Size([128, 128, 125]) 675\n",
      "torch.Size([128, 128, 125]) 676\n",
      "torch.Size([128, 128, 125]) 677\n",
      "torch.Size([128, 128, 125]) 678\n",
      "torch.Size([128, 128, 125]) 679\n",
      "torch.Size([128, 128, 125]) 680\n",
      "torch.Size([128, 128, 125]) 681\n",
      "torch.Size([128, 128, 125]) 682\n",
      "torch.Size([128, 128, 125]) 683\n",
      "torch.Size([128, 128, 125]) 684\n",
      "torch.Size([128, 128, 125]) 685\n",
      "torch.Size([128, 128, 125]) 686\n",
      "torch.Size([128, 128, 125]) 687\n",
      "torch.Size([128, 128, 125]) 688\n",
      "torch.Size([128, 128, 125]) 689\n",
      "torch.Size([128, 128, 125]) 690\n",
      "torch.Size([128, 128, 125]) 691\n",
      "torch.Size([128, 128, 125]) 692\n",
      "torch.Size([128, 128, 125]) 693\n",
      "torch.Size([128, 128, 125]) 694\n",
      "torch.Size([128, 128, 125]) 695\n",
      "torch.Size([128, 128, 125]) 696\n",
      "torch.Size([128, 128, 125]) 697\n",
      "torch.Size([128, 128, 125]) 698\n",
      "torch.Size([128, 128, 125]) 699\n",
      "torch.Size([128, 128, 125]) 700\n",
      "torch.Size([128, 128, 125]) 701\n",
      "torch.Size([128, 128, 125]) 702\n",
      "torch.Size([128, 128, 125]) 703\n",
      "torch.Size([128, 128, 125]) 704\n",
      "torch.Size([128, 128, 125]) 705\n",
      "torch.Size([128, 128, 125]) 706\n",
      "torch.Size([128, 128, 125]) 707\n",
      "torch.Size([128, 128, 125]) 708\n",
      "torch.Size([128, 128, 125]) 709\n",
      "torch.Size([128, 128, 125]) 710\n",
      "torch.Size([128, 128, 125]) 711\n",
      "torch.Size([128, 128, 125]) 712\n",
      "torch.Size([128, 128, 125]) 713\n",
      "torch.Size([128, 128, 125]) 714\n",
      "torch.Size([128, 128, 125]) 715\n",
      "torch.Size([128, 128, 125]) 716\n",
      "torch.Size([128, 128, 125]) 717\n",
      "torch.Size([128, 128, 125]) 718\n",
      "torch.Size([128, 128, 125]) 719\n",
      "torch.Size([128, 128, 125]) 720\n",
      "torch.Size([128, 128, 125]) 721\n",
      "torch.Size([128, 128, 125]) 722\n",
      "torch.Size([128, 128, 125]) 723\n",
      "torch.Size([128, 128, 125]) 724\n",
      "torch.Size([128, 128, 125]) 725\n",
      "torch.Size([128, 128, 125]) 726\n",
      "torch.Size([128, 128, 125]) 727\n",
      "torch.Size([128, 128, 125]) 728\n",
      "torch.Size([128, 128, 125]) 729\n",
      "torch.Size([128, 128, 125]) 730\n",
      "torch.Size([128, 128, 125]) 731\n",
      "torch.Size([128, 128, 125]) 732\n",
      "torch.Size([128, 128, 125]) 733\n",
      "torch.Size([128, 128, 125]) 734\n",
      "torch.Size([128, 128, 125]) 735\n",
      "torch.Size([128, 128, 125]) 736\n",
      "torch.Size([128, 128, 125]) 737\n",
      "torch.Size([128, 128, 125]) 738\n",
      "torch.Size([128, 128, 125]) 739\n",
      "torch.Size([128, 128, 125]) 740\n",
      "torch.Size([128, 128, 125]) 741\n",
      "torch.Size([128, 128, 125]) 742\n",
      "torch.Size([128, 128, 125]) 743\n",
      "torch.Size([128, 128, 125]) 744\n",
      "torch.Size([128, 128, 125]) 745\n",
      "torch.Size([128, 128, 125]) 746\n",
      "torch.Size([128, 128, 125]) 747\n",
      "torch.Size([128, 128, 125]) 748\n",
      "torch.Size([128, 128, 125]) 749\n",
      "torch.Size([128, 128, 125]) 750\n",
      "torch.Size([128, 128, 125]) 751\n",
      "torch.Size([128, 128, 125]) 752\n",
      "torch.Size([128, 128, 125]) 753\n",
      "torch.Size([128, 128, 125]) 754\n",
      "torch.Size([128, 128, 125]) 755\n",
      "torch.Size([128, 128, 125]) 756\n",
      "torch.Size([128, 128, 125]) 757\n",
      "torch.Size([128, 128, 125]) 758\n",
      "torch.Size([128, 128, 125]) 759\n",
      "torch.Size([128, 128, 125]) 760\n",
      "torch.Size([128, 128, 125]) 761\n",
      "torch.Size([128, 128, 125]) 762\n",
      "torch.Size([128, 128, 125]) 763\n",
      "torch.Size([128, 128, 125]) 764\n",
      "torch.Size([128, 128, 125]) 765\n",
      "torch.Size([128, 128, 125]) 766\n",
      "torch.Size([128, 128, 125]) 767\n",
      "torch.Size([128, 128, 125]) 768\n",
      "torch.Size([128, 128, 125]) 769\n",
      "torch.Size([128, 128, 125]) 770\n",
      "torch.Size([128, 128, 125]) 771\n",
      "torch.Size([128, 128, 125]) 772\n",
      "torch.Size([128, 128, 125]) 773\n",
      "torch.Size([128, 128, 125]) 774\n",
      "torch.Size([128, 128, 125]) 775\n",
      "torch.Size([128, 128, 125]) 776\n",
      "torch.Size([128, 128, 125]) 777\n",
      "torch.Size([128, 128, 125]) 778\n",
      "torch.Size([128, 128, 125]) 779\n",
      "torch.Size([128, 128, 125]) 780\n",
      "torch.Size([128, 128, 125]) 781\n",
      "torch.Size([128, 128, 125]) 782\n",
      "torch.Size([128, 128, 125]) 783\n",
      "torch.Size([128, 128, 125]) 784\n",
      "torch.Size([128, 128, 125]) 785\n",
      "torch.Size([128, 128, 125]) 786\n",
      "torch.Size([128, 128, 125]) 787\n",
      "torch.Size([128, 128, 125]) 788\n",
      "torch.Size([128, 128, 125]) 789\n",
      "torch.Size([128, 128, 125]) 790\n",
      "torch.Size([128, 128, 125]) 791\n",
      "torch.Size([128, 128, 125]) 792\n",
      "torch.Size([128, 128, 125]) 793\n",
      "torch.Size([128, 128, 125]) 794\n",
      "torch.Size([128, 128, 125]) 795\n",
      "torch.Size([128, 128, 125]) 796\n",
      "torch.Size([128, 128, 125]) 797\n",
      "torch.Size([128, 128, 125]) 798\n",
      "torch.Size([128, 128, 125]) 799\n",
      "torch.Size([128, 128, 125]) 800\n",
      "torch.Size([128, 128, 125]) 801\n",
      "torch.Size([128, 128, 125]) 802\n",
      "torch.Size([128, 128, 125]) 803\n",
      "torch.Size([128, 128, 125]) 804\n",
      "torch.Size([128, 128, 125]) 805\n",
      "torch.Size([128, 128, 125]) 806\n",
      "torch.Size([128, 128, 125]) 807\n",
      "torch.Size([128, 128, 125]) 808\n",
      "torch.Size([128, 128, 125]) 809\n",
      "torch.Size([128, 128, 125]) 810\n",
      "torch.Size([128, 128, 125]) 811\n",
      "torch.Size([128, 128, 125]) 812\n",
      "torch.Size([128, 128, 125]) 813\n",
      "torch.Size([128, 128, 125]) 814\n",
      "torch.Size([128, 128, 125]) 815\n",
      "torch.Size([128, 128, 125]) 816\n",
      "torch.Size([128, 128, 125]) 817\n",
      "torch.Size([128, 128, 125]) 818\n",
      "torch.Size([128, 128, 125]) 819\n",
      "torch.Size([128, 128, 125]) 820\n",
      "torch.Size([128, 128, 125]) 821\n",
      "torch.Size([128, 128, 125]) 822\n",
      "torch.Size([128, 128, 125]) 823\n",
      "torch.Size([128, 128, 125]) 824\n",
      "torch.Size([128, 128, 125]) 825\n",
      "torch.Size([128, 128, 125]) 826\n",
      "torch.Size([128, 128, 125]) 827\n",
      "torch.Size([128, 128, 125]) 828\n",
      "torch.Size([128, 128, 125]) 829\n",
      "torch.Size([128, 128, 125]) 830\n",
      "torch.Size([128, 128, 125]) 831\n",
      "torch.Size([128, 128, 125]) 832\n",
      "torch.Size([128, 128, 125]) 833\n",
      "torch.Size([128, 128, 125]) 834\n",
      "torch.Size([128, 128, 125]) 835\n",
      "torch.Size([128, 128, 125]) 836\n",
      "torch.Size([128, 128, 125]) 837\n",
      "torch.Size([128, 128, 125]) 838\n",
      "torch.Size([128, 128, 125]) 839\n",
      "torch.Size([128, 128, 125]) 840\n",
      "torch.Size([128, 128, 125]) 841\n",
      "torch.Size([128, 128, 125]) 842\n",
      "torch.Size([128, 128, 125]) 843\n",
      "torch.Size([128, 128, 125]) 844\n",
      "torch.Size([128, 128, 125]) 845\n",
      "torch.Size([128, 128, 125]) 846\n",
      "torch.Size([128, 128, 125]) 847\n",
      "torch.Size([128, 128, 125]) 848\n",
      "torch.Size([128, 128, 125]) 849\n",
      "torch.Size([128, 128, 125]) 850\n",
      "torch.Size([128, 128, 125]) 851\n",
      "torch.Size([128, 128, 125]) 852\n",
      "torch.Size([128, 128, 125]) 853\n",
      "torch.Size([128, 128, 125]) 854\n",
      "torch.Size([128, 128, 125]) 855\n",
      "torch.Size([128, 128, 125]) 856\n",
      "torch.Size([128, 128, 125]) 857\n",
      "torch.Size([128, 128, 125]) 858\n",
      "torch.Size([128, 128, 125]) 859\n",
      "torch.Size([128, 128, 125]) 860\n",
      "torch.Size([128, 128, 125]) 861\n",
      "torch.Size([128, 128, 125]) 862\n",
      "torch.Size([128, 128, 125]) 863\n",
      "torch.Size([128, 128, 125]) 864\n",
      "torch.Size([128, 128, 125]) 865\n",
      "torch.Size([128, 128, 125]) 866\n",
      "torch.Size([128, 128, 125]) 867\n",
      "torch.Size([128, 128, 125]) 868\n",
      "torch.Size([128, 128, 125]) 869\n",
      "torch.Size([128, 128, 125]) 870\n",
      "torch.Size([128, 128, 125]) 871\n",
      "torch.Size([128, 128, 125]) 872\n",
      "torch.Size([128, 128, 125]) 873\n",
      "torch.Size([128, 128, 125]) 874\n",
      "torch.Size([128, 128, 125]) 875\n",
      "torch.Size([128, 128, 125]) 876\n",
      "torch.Size([128, 128, 125]) 877\n",
      "torch.Size([128, 128, 125]) 878\n",
      "torch.Size([128, 128, 125]) 879\n",
      "torch.Size([128, 128, 125]) 880\n",
      "torch.Size([128, 128, 125]) 881\n",
      "torch.Size([128, 128, 125]) 882\n",
      "torch.Size([128, 128, 125]) 883\n",
      "torch.Size([128, 128, 125]) 884\n",
      "torch.Size([128, 128, 125]) 885\n",
      "torch.Size([128, 128, 125]) 886\n",
      "torch.Size([128, 128, 125]) 887\n",
      "torch.Size([128, 128, 125]) 888\n",
      "torch.Size([128, 128, 125]) 889\n",
      "torch.Size([128, 128, 125]) 890\n",
      "torch.Size([128, 128, 125]) 891\n",
      "torch.Size([128, 128, 125]) 892\n",
      "torch.Size([128, 128, 125]) 893\n",
      "torch.Size([128, 128, 125]) 894\n",
      "torch.Size([128, 128, 125]) 895\n",
      "torch.Size([128, 128, 125]) 896\n",
      "torch.Size([128, 128, 125]) 897\n",
      "torch.Size([128, 128, 125]) 898\n",
      "torch.Size([128, 128, 125]) 899\n",
      "torch.Size([128, 128, 125]) 900\n",
      "torch.Size([128, 128, 125]) 901\n",
      "torch.Size([128, 128, 125]) 902\n",
      "torch.Size([128, 128, 125]) 903\n",
      "torch.Size([128, 128, 125]) 904\n",
      "torch.Size([128, 128, 125]) 905\n",
      "torch.Size([128, 128, 125]) 906\n",
      "torch.Size([128, 128, 125]) 907\n",
      "torch.Size([128, 128, 125]) 908\n",
      "torch.Size([128, 128, 125]) 909\n",
      "torch.Size([128, 128, 125]) 910\n",
      "torch.Size([128, 128, 125]) 911\n",
      "torch.Size([128, 128, 125]) 912\n",
      "torch.Size([128, 128, 125]) 913\n",
      "torch.Size([128, 128, 125]) 914\n",
      "torch.Size([128, 128, 125]) 915\n",
      "torch.Size([128, 128, 125]) 916\n",
      "torch.Size([128, 128, 125]) 917\n",
      "torch.Size([128, 128, 125]) 918\n",
      "torch.Size([128, 128, 125]) 919\n",
      "torch.Size([128, 128, 125]) 920\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1785856 into shape (128,128,125)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, a)\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mAgricultureDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     13\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m---> 14\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\numpy\\lib\\format.py:831\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    829\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 831\u001b[0m         array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1785856 into shape (128,128,125)"
     ]
    }
   ],
   "source": [
    "for a, i in enumerate(train_dataset):\n",
    "    print(i[0].shape, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11749951,
     "sourceId": 98450,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
