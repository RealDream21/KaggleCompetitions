{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import lightning\n",
    "import sklearn\n",
    "import kornia.augmentation as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = sklearn.model_selection.train_test_split(pd.read_csv('train.csv'), train_size=0.8)\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgricultureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.target_shape = (128, 128, 125)\n",
    "        self.has_labels = 'label' in df.columns\n",
    "        self.transform = transform\n",
    "        self.transformations = nn.Sequential(\n",
    "            K.RandomHorizontalFlip(p=0.3),     \n",
    "            K.RandomVerticalFlip(p=0.3),\n",
    "            K.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05), p=0.5)\n",
    "        )   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx].id)\n",
    "        img = np.load(img_path) \n",
    "        \n",
    "        H, W, D = img.shape\n",
    "        TH, TW, TD = self.target_shape\n",
    "\n",
    "        padded = np.zeros(self.target_shape, dtype=np.float32)\n",
    "\n",
    "        copy_H = min(H, TH)\n",
    "        copy_W = min(W, TW)\n",
    "        copy_D = min(D, TD)\n",
    "\n",
    "        padded[:copy_H, :copy_W, :copy_D] = img[:copy_H, :copy_W, :copy_D]\n",
    "        multi_spectral_image = torch.from_numpy(padded).permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            multi_spectral_image = self.transformations(multi_spectral_image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = float(self.df.iloc[idx].label)\n",
    "            return multi_spectral_image, label\n",
    "        else:\n",
    "            return multi_spectral_image, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AgricultureDataset(train_df, 'ot/ot', transform=False)\n",
    "valid_dataset = AgricultureDataset(valid_df, 'ot/ot')\n",
    "test_dataset = AgricultureDataset(test_df, 'ot/ot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 16, shuffle=True, num_workers=num_workers)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size = 16, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_3_3_1 = nn.Conv3d(in_channels=125, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.batch_norm_1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_3_3_2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.batch_norm_2 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.residual_conv = nn.Conv3d(in_channels=125, out_channels=128, kernel_size=1)\n",
    "        \n",
    "        self.final_relu = nn.ReLU()\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.output = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if x.dim() == 4:\n",
    "            batch, channels, height, width = x.shape\n",
    "            x = x.reshape(batch, channels, 1, height, width)\n",
    "\n",
    "        x_res = self.residual_conv(x)\n",
    "        \n",
    "        x_forwarded = self.conv_3_3_1(x)\n",
    "        x_forwarded = self.batch_norm_1(x_forwarded)\n",
    "        x_forwarded = self.relu(x_forwarded)\n",
    "        x_forwarded = self.conv_3_3_2(x_forwarded)\n",
    "        x_forwarded = self.batch_norm_2(x_forwarded)\n",
    "        \n",
    "        x = x_res + x_forwarded \n",
    "        x = self.final_relu(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMyModel(lightning.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model.float()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.float()\n",
    "        preds = self.model(x).squeeze(dim=1)\n",
    "        loss = torch.nn.functional.mse_loss(preds, y)\n",
    "        loss = loss.float()\n",
    "        self.log_dict({'loss':loss})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.float()\n",
    "        preds = self.model(x).squeeze(dim=1)\n",
    "        loss = torch.nn.functional.mse_loss(preds, y)\n",
    "        loss = loss.item()\n",
    "        self.log_dict({'val_loss':loss})\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        with torch.no_grad():\n",
    "            x, _ = batch\n",
    "            preds = self.model(x).squeeze(dim=1)\n",
    "            return preds\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "trainableModel = LitMyModel(model)\n",
    "callbacks = [lightning.pytorch.callbacks.EarlyStopping('val_loss'), lightning.pytorch.callbacks.ModelCheckpoint(monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Fabi\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | MyModel | 454 K  | train\n",
      "------------------------------------------\n",
      "454 K     Trainable params\n",
      "0         Non-trainable params\n",
      "454 K     Total params\n",
      "1.816     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f84468194c44e5382684c2751354583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabi\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "C:\\Users\\Fabi\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Fabi\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d514f49e7f9406c9d78cad5e11bbb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf284fcde85548b580b5ff3bed1ca4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73dc97fe117411c8d744f8d0d86508e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ab034d202c4a46990e1f2986114d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cdc9dbfecd457d961068b8af8c561a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7657fb1204314c99ab96b68d1d4e1f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6acf62d10214327a3052ed7ae70bb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaf07ec9e0e407aad4b08b22ddfdf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ee7570344744dbac6f12b8ed779d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba116647749b4b9ab5bd654d4743c035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c792b22737446e6bfd057d05dde2987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252aad55866c4d13b88518218fb1a060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = lightning.Trainer(accelerator=device,callbacks=callbacks)\n",
    "trainer.fit(trainableModel, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Fabi/Desktop/KaggleCompetitions/Beyond Visible Spectrum AI for Agriculture 2025/lightning_logs/version_5/checkpoints/epoch=0-step=109.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[330], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainedModel \u001b[38;5;241m=\u001b[39m \u001b[43mLitMyModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlightning_logs/version_5/checkpoints/epoch=0-step=109.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\utilities\\model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m     )\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\core\\module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1579\u001b[0m \n\u001b[0;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m _load_from_checkpoint(\n\u001b[0;32m   1582\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   1583\u001b[0m         checkpoint_path,\n\u001b[0;32m   1584\u001b[0m         map_location,\n\u001b[0;32m   1585\u001b[0m         hparams_file,\n\u001b[0;32m   1586\u001b[0m         strict,\n\u001b[0;32m   1587\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1588\u001b[0m     )\n\u001b[0;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\pytorch\\core\\saving.py:63\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m map_location \u001b[38;5;241m=\u001b[39m map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[1;32m---> 63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[0;32m     66\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[0;32m     67\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     68\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\lightning\\fabric\\utilities\\cloud_io.py:59\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[0;32m     55\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     56\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m     61\u001b[0m         f,\n\u001b[0;32m     62\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[0;32m     64\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\fsspec\\spec.py:1310\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1310\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[0;32m   1311\u001b[0m         path,\n\u001b[0;32m   1312\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   1313\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[0;32m   1314\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[0;32m   1315\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[0;32m   1316\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1317\u001b[0m     )\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\fsspec\\implementations\\local.py:200\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\fsspec\\implementations\\local.py:364\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\licenta\\lib\\site-packages\\fsspec\\implementations\\local.py:369\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 369\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[0;32m    371\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Fabi/Desktop/KaggleCompetitions/Beyond Visible Spectrum AI for Agriculture 2025/lightning_logs/version_5/checkpoints/epoch=0-step=109.ckpt'"
     ]
    }
   ],
   "source": [
    "trainedModel = LitMyModel.load_from_checkpoint('lightning_logs/version_5/checkpoints/epoch=0-step=109.ckpt', model=MyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "for batch in test_dataloader:\n",
    "    preds = [int(x) for x in trainedModel.predict_step(batch, 0)]\n",
    "    all_preds.extend(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11749951,
     "sourceId": 98450,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
