{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import lightning\n",
    "import sklearn\n",
    "import kornia.augmentation as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = sklearn.model_selection.train_test_split(pd.read_csv('train.csv'), train_size=0.8)\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgricultureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.target_shape = (128, 128, 125)\n",
    "        self.has_labels = 'label' in df.columns\n",
    "        self.transform = transform\n",
    "        self.transformations = torch.nn.Sequential(\n",
    "            K.RandomHorizontalFlip(p=0.3),     \n",
    "            K.RandomVerticalFlip(p=0.3),\n",
    "            K.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05), p=0.5)\n",
    "        )   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx].id)\n",
    "        img = np.load(img_path) \n",
    "        \n",
    "        H, W, D = img.shape\n",
    "        TH, TW, TD = self.target_shape\n",
    "\n",
    "        padded = np.zeros(self.target_shape, dtype=np.float32)\n",
    "\n",
    "        copy_H = min(H, TH)\n",
    "        copy_W = min(W, TW)\n",
    "        copy_D = min(D, TD)\n",
    "\n",
    "        padded[:copy_H, :copy_W, :copy_D] = img[:copy_H, :copy_W, :copy_D]\n",
    "        multi_spectral_image = torch.from_numpy(padded).permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            multi_spectral_image = self.transformations(multi_spectral_image)\n",
    "            multi_spectral_image = multi_spectral_image.squeeze(dim=0)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = float(self.df.iloc[idx].label)\n",
    "            return multi_spectral_image, label\n",
    "        else:\n",
    "            return multi_spectral_image, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AgricultureDataset(train_df, 'ot/ot', transform=True)\n",
    "valid_dataset = AgricultureDataset(valid_df, 'ot/ot')\n",
    "test_dataset = AgricultureDataset(test_df, 'ot/ot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 128, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 16, shuffle=True, num_workers=num_workers)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size = 16, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_3_3_1 = nn.Conv3d(in_channels=125, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.batch_norm_1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_3_3_2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.batch_norm_2 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.residual_conv = nn.Conv3d(in_channels=125, out_channels=128, kernel_size=1)\n",
    "        \n",
    "        self.final_relu = nn.ReLU()\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.output = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if x.dim() == 4:\n",
    "            batch, channels, height, width = x.shape\n",
    "            x = x.reshape(batch, channels, 1, height, width)\n",
    "\n",
    "        x_res = self.residual_conv(x)\n",
    "        \n",
    "        x_forwarded = self.conv_3_3_1(x)\n",
    "        x_forwarded = self.batch_norm_1(x_forwarded)\n",
    "        x_forwarded = self.relu(x_forwarded)\n",
    "        x_forwarded = self.conv_3_3_2(x_forwarded)\n",
    "        x_forwarded = self.batch_norm_2(x_forwarded)\n",
    "        \n",
    "        x = x_res + x_forwarded \n",
    "        x = self.final_relu(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMyModel(lightning.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model.float()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.float()\n",
    "        preds = self.model(x).squeeze(dim=1)\n",
    "        loss = torch.nn.functional.mse_loss(preds, y)\n",
    "        loss = loss.float()\n",
    "        self.log_dict({'loss':loss})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.float()\n",
    "        preds = self.model(x).squeeze(dim=1)\n",
    "        loss = torch.nn.functional.mse_loss(preds, y)\n",
    "        loss = loss.item()\n",
    "        self.log_dict({'val_loss':loss})\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        with torch.no_grad():\n",
    "            x, _ = batch\n",
    "            x = x.to(self.device)\n",
    "            preds = self.model(x).squeeze(dim=1)\n",
    "            return preds\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "trainableModel = LitMyModel(model)\n",
    "callbacks = [lightning.pytorch.callbacks.EarlyStopping('val_loss'), lightning.pytorch.callbacks.ModelCheckpoint(monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(accelerator=device,callbacks=callbacks)\n",
    "trainer.fit(trainableModel, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = LitMyModel.load_from_checkpoint('lightning_logs/version_5/checkpoints/epoch=6-step=763.ckpt', model=MyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "for batch in test_dataloader:\n",
    "    preds = [int(x) for x in trainedModel.predict_step(batch, 0)]\n",
    "    all_preds.extend(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11749951,
     "sourceId": 98450,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
