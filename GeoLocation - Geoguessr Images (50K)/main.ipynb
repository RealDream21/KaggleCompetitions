{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdc524-8463-46b3-a042-840e72950eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Africa -> 0, 2103 total items\n",
    "# Asia -> 1, 8852 total items\n",
    "# Europe -> 2, 18117 total items\n",
    "# North America -> 3, 14502 total items\n",
    "# Oceania -> 4, 2296 total items\n",
    "# South America -> 5, 4125 total items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80206cc6-c456-4b58-868a-357370a721e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de929-2641-4fdf-a372-9e36e7438fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_leaf_files(directory):\n",
    "    try:\n",
    "        children = os.listdir(directory)\n",
    "        child_dirs = [os.path.join(directory, x) for x in children]\n",
    "        total = 0\n",
    "        total += sum([count_leaf_files(x) for x in child_dirs])\n",
    "        return total\n",
    "    except NotADirectoryError as e:\n",
    "        return 1\n",
    "        \n",
    "class GeoGuessrDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.all_files = [x for x in os.listdir(self.img_dir) if 'jpg' in x]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.all_files[idx]\n",
    "        img = torchvision.io.read_image(os.path.join(self.img_dir, filename))\n",
    "        label = torch.tensor(int(filename[0]))\n",
    "        if label >= 1:\n",
    "            label = label - 1\n",
    "        \n",
    "        return img.float(), label.long()\n",
    "            \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519879f3-2527-4e9b-82e0-0895736878d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff9722-39bd-47d1-965d-155c0ebdea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeoGuessrDataset('continents')\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d5420-ab93-4db5-8dcc-9cea37c8b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=8, shuffle=True, num_workers = 0)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=8, shuffle=True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67be44-c03a-4115-b81e-cbc1b3e8c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels = in_channels, out_channels=out_channels, kernel_size = 3, padding=1)\n",
    "        self.maxpool = torch.nn.MaxPool2d(2)\n",
    "        self.activ = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.activ(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced7a26-b1aa-43f3-98ed-697d56f659f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = ConvBlock(3, 16)\n",
    "        self.block2 = ConvBlock(16, 32)\n",
    "        self.block3 = ConvBlock(32, 64)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1)\n",
    "        self.dense1 = torch.nn.Linear(64*192*82, out_features=128)\n",
    "        self.dense2 = torch.nn.Linear(in_features=128, out_features=64)\n",
    "        self.dense3 = torch.nn.Linear(in_features=64, out_features=6)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc92eb4-73fe-43f7-a7e2-3239112272cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(3, 3, 1536, 662).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf50d2-b141-4eb9-922b-f0cbfea909fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608e7a7-ff40-4650-8068-33241af26dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82defdd2-4a2e-49db-99e2-2cb59b64efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    loss_hist = []\n",
    "    acc_hist = []\n",
    "    step_hist = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    i = 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        i += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X).float()\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 50 == 0 and i > 50:\n",
    "            y_pred = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            acc = sklearn.metrics.accuracy_score(y, y_pred)\n",
    "            \n",
    "            print(f'Epoch loss: {loss.item() / len(y)}, acc: {acc}')\n",
    "            loss_hist.append(loss.item() / len(y))\n",
    "            acc_hist.append(acc)\n",
    "            step_hist.append(i)\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94191da-e4af-49e4-bd44-dd57bd053737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fa150-17ef-4881-bcb8-c1cddaefa34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26122c-338f-4808-a833-c98be6566aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db59a3-63f2-4fee-9d4c-2dbc76aea320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "img = dataset[1]\n",
    "print(img)\n",
    "\n",
    "# Dacă e un tuple (imagine, etichetă), extrage doar imaginea:\n",
    "if isinstance(img, (tuple, list)):\n",
    "    img = img[0]\n",
    "\n",
    "# Dacă imaginea e un tensor PyTorch, convertește-l\n",
    "if isinstance(img, torch.Tensor):\n",
    "    img = img.permute(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "    img = img.numpy()\n",
    "\n",
    "# Dacă e nevoie, ajustează forma (opțional, dacă știi forma corectă)\n",
    "# img = img.reshape((662, 1536, 3))  # doar dacă e o imagine plată\n",
    "\n",
    "# Afișează imaginea\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
